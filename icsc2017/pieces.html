<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>ICSC2017 Conference</title>

    <!-- Bootstrap -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <!-- icsc2017 styles -->
    <link href="css/style.css" rel="stylesheet">
    <!-- Montserrat typo -->
    <link href="css/fonts.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <link rel="shortcut icon" href="img/favicon.ico"/>
  </head>
  <body>
    <header>
      <nav class="navbar navbar-default">
        <div class="container">
          <!-- Brand and toggle get grouped for better mobile display -->
          <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="./"><img class="img-responsive" src="./img/logo_ICSC2017.svg" alt="ICSC2017"></a>
          </div>

          <!-- Collect the nav links, forms, and other content for toggling -->
          <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav">
              <li><a href="./">About</a></li>
              <li class="active"><a href="./program.html">Program<span class="sr-only">(current)</span></a></li>
              <li><a href="./workshops.html">Workshops</a></li>
              <li><a href="./travel.html">Travel</a></li>
              <li><a href="./dates.html">Dates</a></li>
              <li><a href="./call.html">Submissions</a></li>
              <li><a href="./registration.html">Registration</a></li>
            </ul>

          </div><!-- /.navbar-collapse -->
        </div><!-- /.container-fluid -->
      </nav>
  </header>

  <div class="page-header">
    <div class="container">
      <h1>ICSC2017</h1>
    </div>
  </div>

  <div class="content">
    <div class="container">
      <h2>About the Pieces</h2>

	<p style="margin:2em 0;">Program notes provided by the composers.</p>


	  <div class="piece" id="Calzada-Scheps">
	  <p class="piece_title">Micrófono Abierto/Open Mic<span class="year">[2017]</span></p>
	  <p class="piece_subtitle">for voice and live processing</p>
	  <p class="composer">Guzmán Calzada (Uruguay, 1995), Sofía Scheps (Uruguay, 1987)</p>
	  <p class="notes">The installation proposes to attend to the acoustic
	  qualities of an architectural space as an invisible dynamic layer,
	  which can be activated or reconstructed by the voice. A simple written
	  instruction invites the people to vocalize in front of a dynamic
	  microphone. By doing so, they activate a system which responds
	  recreating artificially (through sound synthesis and amplification) the
	  space’s acoustic response, given by its architectural dimensions. The
	  sound of the voice is not amplified, so that a situation of
	  estrangement is built around the use of the microphone: it suggests the
	  possibility of amplifiying the voice, but it doesn’t do it. Instead, it
	  activates the artificial acoustic response of the room.</p>
	  <p class="notes">The signal picked up by the microphone is analyzed by
	  Csound, estimating the fundamental frequency of the voice. If this
	  frequency falls within a certain range of frequencies – close to the
	  frequencies of the standing waves that occurin the room – the system
	  turns on a note with the corresponding standing wave frequency. The
	  instrument consists of an oscillator that reads a sinusoidal wave, and
	  is multiplied by an amplitude envelope, with delicate treatment.</p>

	  </div>


	  <div class="piece" id="Francioni">
	  <p class="piece_title">CLUSTER Vfm<span class="year">[2017]</span></p>
	  <p class="piece_subtitle">version for fixed media</p>
	  <p class="composer">Enrico Francioni (Italy, 1959)</p>
	  <p class="notes">CLUSTER Vfm (stereo version on fixed medium) can be
	  considered as one of the possible versions of CLUSTER. The composition
	  consists of sixteen sequences and each sequence ends, or opens, with a
	  cluster. It has an overall shape that we could define as a speculative
	  type; this element becomes the extended criterion to the details of the
	  material as well as to the substance of the processing principles and
	  the spatialization / localization of the material. The whole work is,
	  in the first part, the construction and, in the second, the
	  decomposition (in time and space) of textures and sound agglomerations
	  dominated all by the interval of fourth.</p>
	  <p class="notes">CLUSTER Vfm is the CLUSTER V (for percussion, live
	  electronics and support sounds) version on stereo. The material is of
	  instrumental origin (vibraphone); It is made in shape: original,
	  elaborate, or continuum. Csound's role: events come into a Csound
	  algorithm, then reproposed, or elaborated, after a time lag. Elsewhere
	  the events processed are reproposed elaborated after a delay. The
	  original (processed or not) material is output in output with the
	  processed one. Types of signal processing: original, delayed but
	  unprocessed, elaborate, delayed and elaborate. The continuum is
	  derived from a single instrumental sound [B4] then processed with
	  analysis and resuscitation (Phase-vocoder) to create sound bands, up to
	  clusters. Effects made with Csound and applied to the signal:
	  distortion, flanger, harmonizer, randomization, remodulation, reverse
	  reading, analysis / resynthesis, delay.</p>

	  <div class="player">
	  <audio controls="controls">
	  	<source src="music/Francioni_CLUSTER_Vfm.ogg" type="audio/ogg">
	  </audio>
	  </div>

	  </div>


	  <div class="piece" id="Avantaggiato">
	  <p class="piece_title">THREE MINIATURES<span class="year">[2016]</span></p>
	  <p class="piece_subtitle" style="margin-left:2em">I. Minus one<br>II. Sonom<br>III. Ordi ventilo</p>
	  <p class="composer">Massimo Vito Avantaggiato (Italy, 1974)</p>
	  <p class="notes">In these pieces I only used sounds derived from wind,
	  industrial or domestic fans/ventilators and water droplets. In this
	  acousmatic miniatures the intervention of man on nature is represented
	  by computational strong modelling of original sounds, while wild nature
	  is represented by natural sounds.

	  <div class="player">
	  <audio controls="controls">
	  	<source src="music/Avantaggiato_Three.Miniatures.ogg" type="audio/ogg">
	  </audio>
	  </div>

	  </div>


	  <div class="piece" id="Arrell">
	  <p class="piece_title">Carnyx<span class="year">[2017]</span></p>
	  <p class="composer">Chris Arrell (USA, 1970)</p>
	  <p class="notes">A ceremonial and military trumpet, the Carnyx features
	  prominently in contemporary depictions of the Iron Age Celts. Standing
	  10-12 feet in the air when the mouthpiece is brought to the performer's
	  lips, the Carnyx places the bell and mouthpiece on opposite ends of an
	  elongated "S" shape. The bell, typically designed as the head of a wild
	  animal or mythical monster, comes to life with fiery red eyes, wagging
	  tongue, and cacophonous bellows. One can imagine the terror of first
	  encountering an army of Carnyces, the towering heads slowly emerging
	  from the early morning mist with "cries so loud and piercing, that the
	  noise seemed to come not from human voices and trumpets, but from the
	  whole countryside at once". (Polybius, Histories, II, 29). </p>
	  <p class="notes">I used Ircam's OpenMusic to build algorithms for the
	  generation of <tt>.orc</tt> and <tt>.sco</tt> parameters (Csound
	  instruments, note onset, durations, intensity and panning). I then
	  imported the files into Csound for audio synthesis. All sounds were
	  synthesized with Csound.</p>

	  <div class="player">
	  <audio controls="controls">
	  	<source src="music/Arrell_Carnyx.ogg" type="audio/ogg">
	  </audio>
	  </div>

	  </div>


	  <div class="piece" id="Chen">
	  <p class="piece_title">Cycle Etude<span class="year">[2017]</span></p>
	  <p class="composer">Tong Chen (China, 1992)</p>
	  <p class="notes">The inspiration of this piece is that the world is
	  based on cycle. The universe, the solar system, the seasons, the
	  history, etc. are all in cycle development. I hope to search the rule
	  of the world in this piece. In 1948, Pierre Schaeffer recorded the
	  noises made by trains running along railroad tracks, used the analogue
	  recording and editing techniques, he composed the famous piece “Etude
	  aux chemins de fer”, and musique concrete became an important style of
	  electronic music. The word "Cycle" also represents bicycle, so I choose
	  the sounds made by bicycle. 70 years later, I use modern digital audio
	  technology, and composed this piece, would like to pay my respect to
	  Pierre Schaeffer.</p>
	  <p class="notes">The samples of the piece were came from the different
	  sounds of bicycle. I edited the samples in Logic, and used Cabbage
	  plugins to modify the samples, then organized all the materials,
	  finally composed this piece, and I also want to show the life and art
	  are also running in a cycle.</p>

	  <div class="player">
	  <audio controls="controls">
	  	<source src="music/Chen_Cycle.Etude.ogg" type="audio/ogg">
	  </audio>
	  </div>

	  </div>


	  <div class="piece" id="Gogins">
	  <p class="piece_title">Shell<span class="year">[2017]</span></p>
	  <p class="composer">Michael Gogins (USA, 1950)</p>
	  <p class="notes">"Shell" is composed and rendered using csound.node,
	  which embeds Csound in the JavaScript context of NW.js, an application
	  that runs Web pages in the Chrome browser without need of a Web server.
	  The piece is composed using my JavaScript algorithmic composition
	  library Silencio. The piece is based on a parametric Lindenmayer
	  system, which not only generates notes, but also voice-leading
	  transformations that are used to fit the notes into chords. In other
	  words, the Lindenmayer system generates not only the notes, but also
	  the harmony. The score is rendered to audio using Csound. The piece
	  also features graphical sliders that are used to adjust instrument
	  parameters and levels, and a 3-dimensional piano roll display of the
	  generated score.</p>
	  <p class="notes">Csound is used to generate and process all audio. The
	  piano sound is synthesized by the Pianoteq VST plugin, which is a
	  high-quality physical model of a grand piano. The plugin is run in
	  Csound using the <tt>vst4cs</tt> opcodes. All other instruments are
	  synthesized completely by Csound. There are no samples in the piece.
	  Instrumental sounds are routed to effects and outputs using the signal
	  flow graph opcodes.</p>

	  </div>


	  <div class="piece" id="Carneiro">
	  <p class="piece_title">Nakx<span class="year">[2017]</span></p>
	  <p class="composer">Marcelo Carneiro (Brazil, 1971)</p>
	  <p class="notes">This works deals with attack-resonance profiles and
	  different allures and forms of continuation imposed to them. Each
	  attack triggers multiple events that gradually develop through time.
	  Accumulations and rarefractions are part of the compositional strategy
	  that deals with a process of unfolding components during the
	  continuum.</p>
	  <p class="notes">All sound objects were created using CsoundQt, and
	  some additional processes were done with the Composer Desktop Project
	  (CDP). The mixing has been done in the Reaper environement.</p>

	  <div class="player">
	  <audio controls="controls">
	  	<source src="music/Carneiro_Nakx.ogg" type="audio/ogg">
	  </audio>
	  </div>

	  </div>


	  <div class="piece" id="Terzaroli">
	  <p class="piece_title">Dark Path #6<span class="year">[2016]</span></p>
	  <p class="composer">Anna Terzaroli (Italy, )</p>
	  <p class="notes">This piece is a part of the “Dark Path” series. This
	  electroacoustic music focuses on sound marks of a sonic landscape. It
	  embodies a sense of history beyond itself. Beyond the analysis of the
	  used recordings, there is a history that is personal. The piece aims to
	  examine and explore the transformative possibilities of the computer
	  music.</p>
	  <p class="notes">Sound material is from a soundscape located in Italy.
	  The sounds were recorded, then they are processed by Csound (AM, RM,
	  FM, Granular synthesis etc.), so they are mixed up by Audacity and
	  Csound.</p>

	  </div>


	  <div class="piece" id="Yang">
	  <p class="piece_title">911<span class="year">[2017]</span></p>
	  <p class="composer">Wanjun Yang (China, 1977)</p>
	  <p class="notes">911 is the emergency call of many countries. Every
	  people may encounter some emergency situation, and need the help of
	  police. They need to dial the numbers on the phone. The sounds of 911
	  may be the hope of the people in need. In this piece, I generated the
	  dialing sounds of 911 in Csound, in order to simulate the analogue
	  phone call, I used the DTMF way to generate the sounds. I believe the
	  sounds of 911 is so important and unforgettable to every people in
	  danger, and the sounds of 911 will not always be the same in the whole
	  procedure of the emergency, the feeling will be changed in different
	  periods. In this piece, I used doppler, reverse, pvsBlur, pitchShift
	  and some other Cabbage plugins to sketch a scene of a building on fire,
	  and some people in danger were rescued and came back to life. The form
	  of this piece is A+B, part A is building on fire, part B is the
	  rescues.</p>
	  <p class="notes">I programmed a simple patch in Csound to generate the
	  DTMF sounds of analogue telephone, and export the sounds of code "9"
	  and "1" as wave files, as source materials of this piece. I choose some
	  FXs in Cabbage, then exported as VST plugins. I copied the Cabbage VST
	  plugins dll files which works correctly into VST plugin folder, and
	  indexed them in Cubase. I imported the material files into Cubase, then
	  I processed the sounds with Cabbage VST plugins to modify them, used
	  different Cabbage FXs in FX chain to get new sounds. After getting all
	  the sounds, arranged them in timeline, and inserted Cabbage FXs to the
	  tracks, and used the envelope to modify the parameters of FXs of the
	  track. In the console of Cubase, I used automation of pan, fader and
	  other parameters to mix all the track, then used compressor in Main out
	  and mastered the piece. Finally exported as FLAC.</p>

	  <div class="player">
	  <audio controls="controls">
	  	<source src="music/Yang_911.ogg" type="audio/ogg">
	  </audio>
	  </div>

	  </div>


	  <div class="piece" id="Kholomiov">
	  <p class="piece_title">Early morning. I can see three planets in the sky<span class="year">[2016]</span></p>
	  <p class="composer">Anton Kholomiov (Russia, 1985)</p>
	  <p class="notes">The music describes the fragile mood of the early
	  morning. It's the state of mind when you are not fully awake but
	  already not sleeping. This is kind of fragile moment when something
	  unexpectant can happen. Like the unusual sight of three planets. There
	  are rare moments when they can be seen. There are actually even four of
	  them if we count the Earth but it obviously can not be seen in the sky.
	  There are too many very good emulators that create ideal piano sound
	  and the living piano seems to be getting on its way to Red List of
	  Threatened Species. That's why I'm very happy to record the live piano
	  and hear it's alive and slightly out of tune sound. And present it to
	  the audience of the confrence.</p>
	  <p class="notes">The whole production cycle was made with Csound. But
	  there are no synthesized sounds! I've recorded live improvisations with
	  grand piano and sontoor. Then I've layered piano in many ways with
	  lot's of reverses and random panning. The piece was made by happy
	  accident too. Initially I was planning to record the completly
	  predefined piece on piano. I've recorded it but at the last moment I
	  decided to record some random passages to fill the possible gaps in the
	  piece. And when I came home I realized that the random passages were
	  the most interesting thing in the whole session :) Then with magical
	  wand of Csound I've scattered them in random ways and through a lot of
	  relistening found out the parameters that generated most interesting
	  sound to me. Then came the birds in the jungle sample and some random
	  natural noises. At the last moment I've recorded the santoor to add
	  some touch of psychodelic state of mind to the piece.</p>

	  <div class="player">
	  <audio controls="controls">
	  	<source src="music/Kholomiov_Early.Morning.ogg" type="audio/ogg">
	  </audio>
	  </div>

	  </div>


	  <div class="piece" id="Conduru">
	  <p class="piece_title">Fábula<span class="year">[2014]</span></p>
	  <p class="composer">Marcelo Machado Conduru (Brazil, 1955)</p>
	  <p class="notes">Starting from the point that sounds are carriers of
	  expressions, the next step could make us think about how to tell a
	  story without words. Or better, to build a scenario where dialogues and
	  other types of speech rule out the words to develop an unword
	  conversation. This is our sensation when the birds share their chants
	  or when the dogs start to bark along the night. Dialogues in some
	  level. Inflections, intonations, rhythm and more vocal details could be
	  summed in a word - Utterance. Sense and Utterance is a hard and
	  subjective theme to dig on, so the focus here is just oriented to -
	  Music and Utterance.</p>
	  <p class="notes">The piece presents types of "speakers" in sections
	  that are named as: 1 - Terrestres; 2 - A Fala das Coisas; 3 - Aéreos; 4
	  - Humanos.</p>
	  <p class="notes">The base for technical proceeds was to keep the sounds
	  crude where gesture and spectral changing could be clear.</p>

	  <div class="player">
	  <audio controls="controls">
	  	<source src="music/Conduru_Fabula.ogg" type="audio/ogg">
	  </audio>
	  </div>

	  </div>


	  <div class="piece" id="Chamorro">
	  <p class="piece_title">Videojuegos, zombies y otros<span class="year">[2017]</span></p>
	  <p class="composer">Lucía Chamorro (Uruguay, 1991)</p>
	  <p class="notes">This experimental composition was programmed using
	  Csound. It resulted from the working process at the Electroacoustic
	  Music Studio in the Universitary School of Music (Montevideo, Uruguay),
	  in the ambit of the Csound workshops.</p>
	  <p class="notes">This composition was made mostly using Csound. I made
	  6 different sections using Csound and then I used a sound editor
	  software just for the assemblage.</p>
	  <p class="notes">Principal opcodes: <tt>fmvoice</tt>, <tt>pan2</tt>,
	  <tt>rand</tt>, <tt>moogvcf</tt>, <tt>vlowres</tt>, <tt>fmmetal</tt>,
	  <tt>reson</tt>, <tt>tambourine</tt>, <tt>diskin2</tt>,
	  <tt>nreverb</tt>, <tt>foscil</tt>, <tt>lowpass2</tt> 
	  <p class="notes">Short audio files:
	  <ul class="notes">
	  <li>twopeaks.aiff (for the <tt>fmmetal</tt> opcode)</li>
	  <li>crunch.wav (from a sound bank) - (for diskin2)</li>
	  <li>oua.wav (recorded by me) - (for diskin2)</li>
	  </ul>
	  </p>

	  </div>


	  <div class="piece" id="Wang">
	  <p class="piece_title">Split<span class="year">[2016]</span></p>
	  <p class="piece_subtitle">3 Movements and Live Audience Participation (First and Second Movement)</p>
	  <p class="composer">Shijie Wang (China, )</p>

	  <p class="notes">This piece is based on author's own experience. One
	  day he was doing a boring, mechanical and repetitive work for quite a
	  long time. At the begining, he was fully concentrating on the job. As
	  time goes on, he started to lose focus, his mind started to think about
	  other non-relevant and logic-less stuff, kind of like a dream, while he
	  was still physically doing the work. Later, he even heard acousmatic
	  voices talking to himself. This piece intents to recreate this mental
	  journey. There are 3 movements. The first one is called "Distracting",
	  which describing the transition between fully focused to distracted.
	  The second movement namely "Overhearing", which means mind and spirit
	  was traveling even further from reality than that was in movement 1.
	  The final movements is called "Splitting", which insinuates that mind
	  and spirit was completely split apart from reality.</p>

	  <p class="notes"><i>First Movement:</i> Sound materials used: Sound of an
	  old-school needle printer, Sound of someone writing, and a Piano.
	  <p class="notes"><i>Second Movement:</i> Composed and performed using
	  Csound. Seven modules were defined for making sound, which are
	  <tt>instr 2</tt>, <tt>instr 20</tt> using <tt>pluck</tt> UGen for a
	  percussion-like sound; <tt>instr 3</tt>, <tt>instr 30</tt> using
	  <tt>oscil</tt> UGen with 3 different tables, <tt>instr 4</tt>, <tt>inst
	  41</tt>, <tt>inst 42</tt> using <tt>diskin2</tt> for sample playback; 5
	  modules manipulates the parameters from all the sound-providing
	  instruments and effects, which are <tt>instr 1</tt>, <tt>instr 10</tt>,
	  <tt>instr 101</tt>, <tt>instr102</tt> and <tt>instr 98</tt>; a delay
	  effect <tt>instr 99</tt>; at last, the <tt>score</tt> part which does
	  the job as its name refers.
	  <p class="notes"><i>Third Movement (not included):</i> This movement
	  includes Live Audience Participation, implemented using Web Audio API,
	  p5.js, node.js and Max/MSP</p>
	  <p><b>Source Code:</b> <a target="_blank"
	  href="https://github.com/Rexhits/Split">https://github.com/Rexhits/Split</a> (Second movement).

	  </div>


	  <div class="piece" id="DelBoca">
	  <p class="piece_title">SaxGui<span class="year">[2004]</span></p>
	  <p class="composer">Basilio Del Boca (Argentina, 1976)</p>
	  <p class="notes">SaxGui, is an acousmatic piece composed starting from
	  the combined sounds processed of Alto Saxo and Guitar. It does not
	  present in its beginning an extramusical program, but it is only a work
	  thought to obtain tensions and distensions in the textures and sonorous
	  densities, given by the sumories of sounds and by rhythmic structures
	  more or less animated.</p>
	  <p class="notes">The work was mixed using Adobe Audition. The original
	  samples of saxophone and guitar were processed using Adobe Audition
	  tools, SMS tools (by Xavier Serra), and specifically Csound: Soundin,
	  sndwarp, Butterworth and clfilt Filters (clfilt) and hrtfer. Moreover,
	  we used the application Clusters for algorithmic composition (score
	  maker, written in Visual Basic, by Basilio Del Boca), in combination
	  with Csound, with which was used to create specific sections of the
	  piece.</p>

	  <div class="player">
	  <audio controls="controls">
	  	<source src="music/DelBoca_SaxGui.ogg" type="audio/ogg">
	  </audio>
	  </div>

	  </div>


	  <div class="piece" id="Secco">
	  <p class="piece_title">Pulso Interior <span class="year">[2017]</span></p>
	  <p class="composer">Leonardo Secco (Uruguay&ndash;Canada, 1966)</p>
	  <p class="notes">The 450 bpm pulse acts as a “binder” to sustain a
	  continuously transforming polyrhythm. This background pulse guides the
	  piece and acts as “hidden” support, allowing a complex control of all
	  the parameters to define a multi level rhythmic fabric. Internal pulse
	  is based on a generative algorithm that allows for the control of the
	  temporal, dynamic, timbral and spatial parameters of the piece by way
	  of human interaction. The result is an immersive electroacoustic
	  performance, in which percussive sounds seem to interact to configure a
	  continuously transforming virtual space.</p>

	  </div>


	  <div class="piece" id="DelPrete">
	  <p class="piece_title">Occupazione dello spazio <span class="year">[2017]</span></p>
	  <p class="composer">Michele Del Prete (Italy, )</p>
	  <p class="notes">Occupazione dello spazio (The occupation of space) is
	  a piece working on three modalities of the taking place of space as
	  sounding space. The piece is composed for a minimum of 8 loudspeakers
	  after the Renaissance polichoral music of the Venetian school. The
	  movements and the positions of the sound events in space determine the
	  nature of the music material (impulses, granulation, filtered white
	  noise) and not vice versa. Changements on the space scale are more
	  important of those on the time scale.</p>
	  <p class="notes">The entire piece is the result of sound synthesis
	  processes entirely made with Csound. Four instruments are used: 1)
	  impulse trains with variable filtering and reverberation; 2) a filtered
	  granulation (with variable filtering), 3 and 4) two distinct filtered
	  noise sources. Several global variables assure interdependency and
	  cross relations among the sounds generated by those instruments. Space
	  is an essential component of Occupazione dello spazio (8 tracks): its
	  elements are spatialized according to three distinct patterns (a
	  "stable-static" figuration for the impulses, an evolving form for the
	  granulation, a double choir constellation for the two noise
	  sources).</p>

	  </div>


	  <div class="piece" id="Boenn">
	  <p class="piece_title">Ad Inifinitum: A tribute to Jean&ndash;Claude Risset<span class="year">[2016]</span></p>
	  <p class="composer">Georg Boenn (Germany, 1965)</p>
	  <p class="notes">'Ad Infinitum' is a tribute to Jean-Claude Risset,
	  composer and pioneer of Computer Music, who died in November 2016. One
	  of his many contributions was an acoustic illusion, the famous infinite
	  glissando. My composition explores his glissando in a polyphonic way by
	  using various transformations. First, the speed of the glissando is
	  continuously changed. Secondly, the harmonic series is used to
	  transpose the glissando and to transform its sound via granular
	  synthesis. Finally, several voices are composed together and projected
	  in circular movements around the auditorium.</p>
	  <p class="notes">The piece uses an implementation of Risset's glissando
	  for csound. The usual sinusoidal oscillators were replaced by
	  square-wave oscillators. The classic algorithm is further modified to
	  have a precise control over the tempo and the direction of the
	  glissando in real-time and by means of an LFO. Several versions were
	  synthesized with interaction in real-time. The sound files were further
	  processed by granular synthesis modules in Cecilia (csound and pyo
	  version). Spatialisation to a 6.1 channel output was synthesized by
	  csound using <tt>vbap</tt> opcodes. Furthermore, a trigonometric formula was
	  developed for generating accelerandi and decelerandi of two pulse
	  stream towards the end of the piece that signify a translation of
	  Risset's pitch-based glissando to a 'glissando' in the rhythmic
	  domain.</p>

	  <div class="player">
	  <audio controls="controls">
	  	<source src="music/Boenn_Ad.Infinitum.ogg" type="audio/ogg">
	  </audio>
	  </div>

	  </div>


	  <div class="piece" id="DiLiscia">
	  <p class="piece_title">Vocalisense <span class="year">[2015]</span></p>
	  <p class="composer">Oscar Pablo Di Liscia (Argentina, 1955)</p>
	  <p class="notes">The title is a portmanteau for Vocalise and Sense. A
	  vocalise is a very well known kind of musical piece, and Sense stands
	  for the name of the vocal ensemble Nonsense (whose members recorded the
	  source sounds of the work). The source sounds are both speech (normal,
	  whispered, shouted) and sung (sustained eight-note chords with
	  different vowels). However, these two categories are combined or
	  transformed the one in the other trough several synthesis and
	  processing techniques. Since the work was conceived for a two dimension
	  surround sound system using the Ambisonics spatialisation technique,
	  the exploration of several “spatial paradoxes” (such as the spatial
	  dissociation of sounds from a single vocal source, the spatial
	  projection of the constituent elements of a word or a syllable, and the
	  spatial dissociation of the direct sound and its room effect) is most
	  relevant in its structure. </p>
	  <p class="notes">The piece was entirely synthesized using Csound.
	  Basically, a set of instruments that perform granulation, espectral
	  based synthesis and spatialisation designed by te author were used. The
	  code and the source sound files used are available if requested.
	  Recording Engineer of the source voice sounds: Natalia Perelman. The
	  final render of the piece is a First Order Ambisonic B-Format and must
	  be decoded for the appropriate set of loudspeakers. The spatialisation
	  of sound treatment is basically 2D (except for the early echoes and
	  dense reverberation).</p>

	  <div class="player">
	  <audio controls="controls">
	  	<source src="music/DiLiscia_Vocalisense.ogg" type="audio/ogg">
	  </audio>
	  </div>

	  </div>


	  <div class="piece" id="DeSanctis">
	  <p class="piece_title">Al disopra dimorano gli uccelli del cielo, cantano tra le fonde <span class="year">[2007]</span></p>
	  <p class="composer">Fabio De Sanctis De Benedictis (Italy, 1963)</p>
	  <p class="notes">"Al disopra dimorano gli uccelli del cielo, cantano
	  tra le fronde" is a quadraphonic electroacoustical piece. The title is
	  desumed from a Psalm, and the sound material is taken from recording of
	  bird songs, an explicit reference to Messiaen. The form wants to be a
	  trip towards highness, as if the public was inside an aviary, a
	  resemblance from composer's memory from childhood age. This trip is a
	  metaphysical one, too, because in sciamanism birds are Gods
	  messengers.</p>
	  <p class="notes">Csound and Cmask have been used to edit and spatialize
	  the sounds. Snd, the CCRMA software, has been used to create artificial
	  bird songs, for an interplay between natural and cultural/artificial.
	  The audio files have been finally edited in Ardour, with a final
	  mastering by Jamin, Linux softwares.</p>
	  <p><b>Source Code:</b> <a target="_blank"
	  href="music/DeSanctis_Al.disopra_code.zip">zip file</a>.

	  <div class="player">
	  <audio controls="controls">
	  	<source src="music/DeSanctis_Al.disopra.ogg" type="audio/ogg">
	  </audio>
	  </div>

	  </div>


	  <div class="piece" id="Rhoades">
	  <p class="piece_title">Second Body Awareness<span class="year">[2017]</span></p>
	  <p class="composer">Michael Rhoades (USA, 1956)</p>
	  <p class="notes">Second Body Awareness was composed using Csound, Cmask
	  and AbSynth. The latter was used to create the 4 sound files the piece
	  is comprised of. It was originally intended to be diffused in a 3D
	  cuboid sound environment and is the basis for a 3D/360 visual music
	  piece, currently in progress. Rather than acting as a description of
	  second body awareness, it is meant as an expression of it.</p>

	  <div class="player">
	  <audio controls="controls">
	  	<source src="music/Rhoades_Second.Body.Awareness.ogg" type="audio/ogg">
	  </audio>
	  </div>

	  </div>


	  <div class="piece" id="Heintz">
	  <p class="piece_title">SCP<span class="year">[2016&ndash;2017]</span></p>
	  <p class="composer">Joachim Heintz (Germany, 1961)</p>
	  <p class="notes">Two spaces in alteration. In the first, "real" space:
	  something wants to get out. Direct, beating energy, obviously without
	  recognizable result. In the second, "unreal?" space: resonance of the
	  hits and clashes, resonances which go their own way, more and more
	  extended &mdash; to which end? SCP ... escape ... scape.</p>
	  <p class="notes">Some recorded samples of different snare drum hits are the main sound source of this piece. All is done in Csound, without any other application:</p>
	  <ul class="notes">
	  <li>the rhythms and the accents</li>
	  <li>the spatialization (vbap for the direct sound)</li>
	  <li>the resonator which is built up by a combination of a Filter (<tt>clfilt</tt>) and six variable comb filters with different chord structures and glissandi of every single unit, put then in an ambisonic setup</li>
	  </ul>
	  <p><b>Source Code:</b> <a target="_blank"
	  href="music/Heintz_SCP_code.zip">zip file</a>.

	  <div class="player">
	  <audio controls="controls">
	  	<source src="music/Heintz_SCP.ogg" type="audio/ogg">
	  </audio>
	  </div>

	  </div>


	  <div class="piece" id="vonReusner">
	  <p class="piece_title">Definierte Lastbedingung <span class="year">[2016]</span></p>
	  <p class="composer">Clemens von Reusner (Germany, 1957)</p>
	  <p class="notes">“Definierte Lastbedingung” (engl. defined load
	  condition) is based upon the sounds of electromagnetic fields as they
	  arise when using electric devices. Numerous recordings of
	  electromagnetic landscapes were made at the "Institute for Electrical
	  Machines, Traction and Drives" (IMAB) of the Technical University of
	  Braunschweig (Germany) with a special microphone. This sound material
	  has little of what a “musical” sound is intrinsically. There is no
	  depth and no momentum. In their noisiness these sounds are static,
	  though moved inside. They usually seem bulky, harsh and repellent, even
	  hermetic as the well known electrical hum. “Defined load condition” (a
	  technical term when testing electrical machines) is about with these
	  sounds which are explored in their structure, reshaped and musically
	  dramatized by the means of the electronic studio. The main frequency
	  of electrical current in Europe is 50 hertz and hence 50 and its
	  multiples is also the numerical key this composition is based upon in a
	  variety of ways. Spatialization: 3rd-order ambisonic. "Definierte
	  Lastbedingung" is also the german contribution to ISCM "World New Music
	  Days" 2017 in Vancouver, Canada.</p>

	  </div>


</div>
</div>

	<!-- =======================          ======================= -->

  <footer>
    <div class="container">
	<div class="row">
      <div class="col-xs-8">
        <a target="_blank" href="http://www.eumus.edu.uy/eme/"><img class="img-responsive center-block emelogo" src="./img/logo_eMe.svg" alt="eMe"></a>
      </div>
	  <div class="col-xs-4" style="text-align:right"> 
	    <a class="contact" target="_blank" href="https://www.eumus.edu.uy/eum/user/724/contact">contact</a>
      </div>
    </div>
    </div>
  </footer>

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="js/bootstrap.min.js"></script>
  </body>
</html>
